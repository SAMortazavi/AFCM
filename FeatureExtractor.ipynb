{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureComputation:\n",
    "    def __init__(self, X, X_base, N_win, N_step, alpha, beta, N_d_point, N_d_win):\n",
    "        \"\"\"\n",
    "        Initialize the feature computation process with necessary parameters.\n",
    "        \n",
    "        Parameters:\n",
    "            X (ndarray): Input spatio-temporal data, shape (L, T)\n",
    "            X_base (float): Background noise data for normalization.\n",
    "            N_win (int): Window size for time dimension.\n",
    "            N_step (int): Step size for sliding window.\n",
    "            alpha (int): Step for energy computation.\n",
    "            beta (float): Threshold for peak count.\n",
    "            N_d_point (int): Spatial window size.\n",
    "            N_d_win (int): Temporal window size.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.X_base = X_base\n",
    "        self.N_win = N_win\n",
    "        self.N_step = N_step\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.N_d_point = N_d_point\n",
    "        self.N_d_win = N_d_win\n",
    "        self.L, self.T = X.shape  # L: spatial points, T: temporal points\n",
    "        self.num_windows = (self.T - self.N_win) // self.N_step + 1  # Total number of sliding windows\n",
    "    \n",
    "    def count_peaks(self, data_segment, threshold=0):\n",
    "        \"\"\"\n",
    "        Count the number of peaks in a data segment above a threshold.\n",
    "        A peak is defined where the signal increases and then decreases.\n",
    "        \"\"\"\n",
    "        peaks = 0\n",
    "        for i in range(1, len(data_segment) - 1):\n",
    "            if data_segment[i] > threshold and data_segment[i] > data_segment[i - 1] and data_segment[i] > data_segment[i + 1]:\n",
    "                peaks += 1\n",
    "        return peaks\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        Compute F_peak and F_energy matrices from input data and then aggregate M_peak and M_energy.\n",
    "        \n",
    "        Returns:\n",
    "            M_peak (ndarray): Aggregated matrix of Peak Features.\n",
    "            M_energy (ndarray): Aggregated matrix of Energy Features.\n",
    "        \"\"\"\n",
    "        # Step 1: Attenuation compensation and standardization\n",
    "        X = self.X / self.X_base  # Normalize input data\n",
    "        \n",
    "        # Initialize matrices\n",
    "        F_peak = np.zeros((self.L, self.num_windows))\n",
    "        F_energy = np.zeros((self.L, self.num_windows))\n",
    "\n",
    "        # Step 2–10: Sliding window computations\n",
    "        for i in range(self.L):  # Iterate over spatial points\n",
    "            for j in range(self.num_windows):  # Sliding windows in time\n",
    "                start_idx = j * self.N_step  # Start index of window\n",
    "                end_idx = start_idx + self.N_win  # End index of window\n",
    "                if end_idx > self.T:  # Avoid exceeding time dimension\n",
    "                    break\n",
    "                window_data = X[i, start_idx:end_idx]  # Extract window of size N_win\n",
    "\n",
    "                # Step 4: Count peaks in the window\n",
    "                F_peak[i, j] = self.count_peaks(window_data)\n",
    "\n",
    "                # Step 5–6: Calculate energy feature\n",
    "                energy_sum = 0\n",
    "                for k in range(self.N_win - 2):  \n",
    "                    if k + self.alpha < len(window_data):\n",
    "                        energy_sum += (window_data[k + self.alpha] - window_data[k]) ** 2\n",
    "\n",
    "                F_energy[i, j] = energy_sum / (self.T * self.X_base)\n",
    "\n",
    "                # Step 8: Apply threshold to energy matrix\n",
    "                if F_peak[i, j] > self.beta:\n",
    "                    F_energy[i, j] = 1\n",
    "\n",
    "        # Initialize aggregated matrices with slightly larger sizes\n",
    "        num_windows_space = (self.L - self.N_d_point) // self.N_d_point + 3\n",
    "        num_windows_combined = (self.num_windows - self.N_d_win) // self.N_d_win + 2\n",
    "\n",
    "        M_peak = np.zeros((num_windows_space, num_windows_combined))\n",
    "        M_energy = np.zeros((num_windows_space, num_windows_combined))\n",
    "\n",
    "        # Step 11–15: Aggregating F_peak and F_energy in spatial and temporal windows\n",
    "        for m in range(self.N_d_point // 2, self.L - self.N_d_point // 2):  # Spatial sliding window\n",
    "            for n in range(0, self.num_windows - self.N_d_win + 1):  # Temporal sliding window\n",
    "                spatial_idx = (m - self.N_d_point // 2) // self.N_d_point\n",
    "                temporal_idx = n // self.N_d_win\n",
    "\n",
    "                # Aggregating F_peak and F_energy\n",
    "                M_peak[spatial_idx, temporal_idx] = np.mean(F_peak[m - self.N_d_point // 2 : m + self.N_d_point // 2 + 1, \n",
    "                                                                n : n + self.N_d_win])\n",
    "                M_energy[spatial_idx, temporal_idx] = np.mean(F_energy[m - self.N_d_point // 2 : m + self.N_d_point // 2 + 1, \n",
    "                                                                        n : n + self.N_d_win])\n",
    "        \n",
    "        # Step to remove rows and columns where all data after them are zero\n",
    "        M_peak = self.trim_zero_rows_and_cols(M_peak)\n",
    "        M_energy = self.trim_zero_rows_and_cols(M_energy)\n",
    "\n",
    "        return M_peak, M_energy\n",
    "\n",
    "    def trim_zero_rows_and_cols(self, matrix):\n",
    "        \"\"\"\n",
    "        Trim rows and columns where all subsequent data are zero.\n",
    "\n",
    "        Parameters:\n",
    "            matrix (ndarray): Input matrix to trim.\n",
    "        \n",
    "        Returns:\n",
    "            trimmed_matrix (ndarray): Matrix after removing unnecessary rows and columns.\n",
    "        \"\"\"\n",
    "        # Find the last non-zero row\n",
    "        non_zero_rows = np.any(matrix != 0, axis=1)\n",
    "        last_non_zero_row = np.where(non_zero_rows)[0].max() + 1 if non_zero_rows.any() else 0\n",
    "\n",
    "        # Find the last non-zero column\n",
    "        non_zero_cols = np.any(matrix != 0, axis=0)\n",
    "        last_non_zero_col = np.where(non_zero_cols)[0].max() + 1 if non_zero_cols.any() else 0\n",
    "\n",
    "        # Trim the matrix\n",
    "        trimmed_matrix = matrix[:last_non_zero_row, :last_non_zero_col]\n",
    "\n",
    "        return trimmed_matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
